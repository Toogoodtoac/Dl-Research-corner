class BEiT3Config:
    encoder_embed_dim = 1024
    encoder_layers = 24
    encoder_attention_heads = 16
    encoder_ffn_embed_dim = 4096
    img_size = 384
    patch_size = 16
    in_chans = 3
    vocab_size = 64010
    num_max_bpe_tokens = 64
    max_source_positions = 1024
    multiway = True
    share_encoder_input_output_embed = False
    no_scale_embedding = False
    layernorm_embedding = False
    normalize_output = True
    no_output_layer = True
    drop_path_rate = 0.2
    dropout = 0.0
    attention_dropout = 0.0
    activation_dropout = 0.0
    max_position_embeddings = 1024
    encoder_normalize_before = True
    activation_fn = "gelu"
    encoder_learned_pos = True
    xpos_rel_pos = False
    xpos_scale_base = 512
    checkpoint_activations = False
    deepnorm = False
    subln = True
    rel_pos_buckets = 0
    max_rel_pos = 0
    bert_init = False
    moe_freq = 0
    moe_expert_count = 0
    moe_top1_expert = False
    moe_gating_use_fp32 = True
    moe_eval_capacity_token_fraction = 0.25
    moe_second_expert_policy = "random"
    moe_normalize_gate_prob_before_dropping = False
    use_xmoe = False
    fsdp = False
    ddp_rank = 0
    flash_attention = False
    scale_length = 2048
    layernorm_eps = 1e-5
